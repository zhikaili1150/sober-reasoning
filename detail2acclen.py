import os
import numpy as np
import pandas as pd
from datasets import load_dataset
from transformers import AutoTokenizer


def analyze_parquet_folder(
    folder_path: str,
    task: str,
    model_name: str = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    save_csv: bool = False,
):
    """
    é€’å½’éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ .parquet æ–‡ä»¶ï¼Œ
    è®¡ç®—å¹³å‡ token length ä¸ extractive_matchã€‚

    å‚æ•°:
        folder_path (str): è¦åˆ†æçš„æ–‡ä»¶å¤¹è·¯å¾„
        model_name (str): ç”¨äºåˆ†è¯çš„æ¨¡å‹åç§°
        save_csv (bool): æ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœ CSV (é»˜è®¤ False)

    è¿”å›:
        dict: {"avg_token_length": float, "avg_extractive_match": float}
    """
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # === æ”¶é›†æ‰€æœ‰ parquet æ–‡ä»¶ ===
    parquet_files = []
    for root, _, files in os.walk(folder_path):
        for f in files:
            if f.endswith(".parquet") and task in f:
                parquet_files.append(os.path.join(root, f))

    if not parquet_files:
        print(f"âš ï¸ No parquet files found under {folder_path}")
        return {"avg_token_length": np.nan, "avg_extractive_match": np.nan}

    print(f"ğŸ” Found {len(parquet_files)} parquet files under {folder_path}")

    records = []

    for parquet_path in parquet_files:
        try:
            details = load_dataset("parquet", data_files=parquet_path, split="train")
            token_lengths, extractive_matches = [], []

            for item in details:
                preds = item.get("predictions", [])
                if preds and isinstance(preds[0], str):
                    tokens = tokenizer.encode(preds[0])
                    token_lengths.append(len(tokens))

                metrics = item.get("metrics", {})
                if isinstance(metrics, dict) and "extractive_match" in metrics:
                    extractive_matches.append(metrics["extractive_match"])

            if token_lengths or extractive_matches:
                avg_len = np.mean(token_lengths) if token_lengths else np.nan
                avg_em = np.mean(extractive_matches) if extractive_matches else np.nan
                records.append({
                    "file": os.path.basename(parquet_path),
                    "avg_token_length": avg_len,
                    "avg_extractive_match": avg_em
                })
                print(f"ğŸ“„ {os.path.basename(parquet_path)} â†’ tokens={avg_len:.1f}, extractive_match={avg_em:.3f}")

        except Exception as e:
            print(f"âŒ Failed to process {parquet_path}: {e}")

    if not records:
        print("âš ï¸ No valid data found.")
        return {"avg_token_length": np.nan, "avg_extractive_match": np.nan}

    df = pd.DataFrame(records)
    avg_len = df["avg_token_length"].mean()
    avg_em = df["avg_extractive_match"].mean()

    print(f"\nâœ… Folder summary â†’ tokens={avg_len:.1f}, extractive_match={avg_em:.3f}")

    if save_csv:
        output_csv = os.path.join(folder_path, "aggregated_metrics.csv")
        df.to_csv(output_csv, index=False)
        print(f"ğŸ’¾ Detailed results saved to: {output_csv}")

    return {"avg_token_length": avg_len, "avg_extractive_match": avg_em}

import os
import pandas as pd

if __name__ == "__main__":
    # === å‚æ•°è®¾ç½® ===
    parent_dir = "/local/scratch/zli2255/workspace/sober-reasoning/result/merge_method/dare_ties/accfmt/details"
    output_csv = os.path.join(parent_dir, "summary.csv")
    model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"

    task_list = ["aime24", "aime25", "amc23", "math_500", "minerva", "olympiadbench"]

    # æ¯ä¸ª folder_name æ±‡æ€»æˆä¸€è¡Œ
    folder_dict = {}

    for folder_name in sorted(os.listdir(parent_dir)):
        folder_path = os.path.join(parent_dir, folder_name)
        if not os.path.isdir(folder_path):
            continue

        print(f"\nğŸ“‚ Processing folder: {folder_name}")
        if folder_name not in folder_dict:
            folder_dict[folder_name] = {"folder_name": folder_name}

        # === æ¯ä¸ª folder å¯¹æ‰€æœ‰ä»»åŠ¡éƒ½è·‘ä¸€ä¸‹ ===
        for task in task_list:
            print(f"   â¤ Task: {task}")

            try:
                result = analyze_parquet_folder(folder_path, task, model_name)

                # å®½è¡¨ç»“æ„ï¼šä¸¤ä¸ªå­—æ®µ
                folder_dict[folder_name][f"{task}_length"] = result.get("avg_token_length", None)
                folder_dict[folder_name][f"{task}_accuracy"] = result.get("avg_extractive_match", None)

            except Exception as e:
                print(f"âš ï¸ Failed: {folder_name} / {task}: {e}")

                # å³ä½¿å¤±è´¥ä¹Ÿç•™ç©ºï¼Œé¿å…ç¼ºåˆ—
                folder_dict[folder_name][f"{task}_length"] = None
                folder_dict[folder_name][f"{task}_accuracy"] = None

    # === è¾“å‡ºå®½è¡¨ CSV ===
    df = pd.DataFrame(folder_dict.values())
    df.to_csv(output_csv, index=False)

    print(f"\nâœ… Wide-format summary saved to {output_csv}")
    print(df)
